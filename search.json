[
  {
    "objectID": "myblog/about.html",
    "href": "myblog/about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "myblog/posts/welcome/index.html",
    "href": "myblog/posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "danl_proj_nba.html#salary-distribution-among-teams",
    "href": "danl_proj_nba.html#salary-distribution-among-teams",
    "title": "Data Analysis Project",
    "section": "Salary Distribution Among Teams",
    "text": "Salary Distribution Among Teams\nLet’s start with the salary distribution among teams using seaborn for visualization. ​​\n\n\n# Handle missing values in 'Salary' by replacing them with the median salary\nmedian_salary = nba['Salary'].median()\nnba['Salary'].fillna(median_salary, inplace=True)\n\n/var/folders/_m/d6jf0jhd2zzdfd5kzdhl_24w0000gn/T/ipykernel_79892/1671011424.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  nba['Salary'].fillna(median_salary, inplace=True)\n\n\n\n# Set the aesthetic style of the plots\nsns.set_style(\"whitegrid\")\n\n# Calculate total salary by team\nteam_salary = (\n    nba\n    .groupby('Team')['Salary']\n    .sum()\n    .reset_index()\n    .sort_values(by='Salary', ascending=False)\n)\n\n# Plot total salary by team\nplt.figure(figsize=(10, 16))\nsns.barplot(data = team_salary,\n            x = 'Salary', y = 'Team',\n            palette = 'coolwarm')\nplt.title('Total Salary Distribution Among NBA Teams')\nplt.xlabel('Total Salary')\nplt.ylabel('Team')\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n\n\n\nThe visualization above displays the total salary distribution among NBA teams, with teams sorted by their total salary expenditure. This bar plot reveals which teams are the biggest spenders on player salaries and which are more conservative. The color gradient provides a visual cue to easily distinguish between the higher and lower spending teams.\nNotice that Portland Trail Blazers has the highest total salary followed by Golden State Warriors and Philadelphia 76ers, and Memphis Grizzlies has the lowest total salary."
  },
  {
    "objectID": "danl_proj_nba.html#player-age-distribution",
    "href": "danl_proj_nba.html#player-age-distribution",
    "title": "Data Analysis Project",
    "section": "Player Age Distribution",
    "text": "Player Age Distribution\nNext, let’s explore the Player Age Distribution across the NBA. We’ll create a histogram to visualize how player ages are distributed, which will help us understand if the league trends younger, older, or has a balanced age mix. ​​\n\n# Convert 'Birthday' column to datetime format\nfrom dateutil import parser\n# nba['Birthday'] = nba['Birthday'].apply(lambda x: parser.parse(x))\n\n# Now, let's calculate the age of each player\n# nba['Age'] = (datetime.now() - nba['Birthday']).dt.days // 365\n\n# Plot the age distribution of NBA players\nplt.figure(figsize=(10, 6))\nsns.histplot(nba['Age'],\n             bins = 15,\n             kde = True,\n             color = 'skyblue')\nplt.title('Age Distribution of NBA Players')\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.show()\n\n\n/Users/bchoe/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n\n\n\n\n\n\n\n\n\nThe histogram above shows the age distribution of NBA players, with a kernel density estimate (KDE) overlay to indicate the distribution shape. The plot helps identify the common ages for NBA players and whether there are significant numbers of very young or older players.\nNotice that the majority of players fall within an age range from 24 to 34. There are few players whose age is above 40."
  },
  {
    "objectID": "danl_proj_nba.html#position-wise-salary-insights",
    "href": "danl_proj_nba.html#position-wise-salary-insights",
    "title": "Data Analysis Project",
    "section": "Position-wise Salary Insights",
    "text": "Position-wise Salary Insights\nMoving on to Position-wise Salary Insights, we’ll examine how average salaries differ across player positions. This analysis could reveal which positions are typically higher-paid, potentially reflecting their value on the basketball court. Let’s create a box plot to visualize the salary distribution for each position. ​​\n\n# Plot salary distribution by player position\nplt.figure(figsize=(10, 6))\nsns.boxplot(data = nba,\n            x = 'Position', y = 'Salary',\n            palette = 'Set2')\nplt.title('Salary Distribution by Position')\nplt.xlabel('Position')\nplt.ylabel('Salary')\nplt.show()\n\n\n\n\n\n\n\n\nThe box plot above illustrates the salary distribution by player position, showcasing the variation in salaries among different positions within the NBA. PG-SG has the highest median salary."
  },
  {
    "objectID": "danl_proj_nba.html#top-10-highest-paid-players",
    "href": "danl_proj_nba.html#top-10-highest-paid-players",
    "title": "Data Analysis Project",
    "section": "Top 10 Highest Paid Players",
    "text": "Top 10 Highest Paid Players\nLastly, we’ll identify the Top 10 Highest Paid Players in the NBA. Let’s visualize this information.\n\n# Identify the top 10 highest paid players\ntop_10_salaries = nba.sort_values(by='Salary', ascending=False).head(10)\n\n# Plot the top 10 highest paid players\nplt.figure(figsize=(12, 8))\nsns.barplot(data = top_10_salaries,\n            x = 'Salary', y = 'PlayerName',\n            palette = 'viridis')\nplt.title('Top 10 Highest Paid NBA Players')\nplt.xlabel('Salary')\nplt.ylabel('Player')\nplt.show()\n\n\n\n\n\n\n\n\nThe bar plot above reveals the top 10 highest-paid NBA players, showcasing those who stand at the pinnacle of the league in terms of salary. This visualization not only highlights the star players who command the highest salaries but also may reflect their marketability, performance, and contribution to their respective teams."
  },
  {
    "objectID": "pandas_basics.html#creating-a-series",
    "href": "pandas_basics.html#creating-a-series",
    "title": "Pandas Basics",
    "section": "Creating a Series",
    "text": "Creating a Series\n\n\n# Creating a Series from a list\ndata = [10, 20, 30, 40, 50]\nseries = pd.Series(data)\nseries\n\n\n\n\n\n\n\n\n0\n\n\n\n\n0\n10\n\n\n1\n20\n\n\n2\n30\n\n\n3\n40\n\n\n4\n50\n\n\n\n\ndtype: int64"
  },
  {
    "objectID": "pandas_basics.html#creating-a-dataframe",
    "href": "pandas_basics.html#creating-a-dataframe",
    "title": "Pandas Basics",
    "section": "Creating a DataFrame",
    "text": "Creating a DataFrame\n\n\n# Creating a DataFrame from a dictionary\ndata = {\n    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"Age\": [25, 30, 35],\n    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\"]\n}\ndf = pd.DataFrame(data)\ndf\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\n\n\n\n\n0\nAlice\n25\nNew York\n\n\n1\nBob\n30\nLos Angeles\n\n\n2\nCharlie\n35\nChicago"
  },
  {
    "objectID": "pandas_basics.html#exploring-data",
    "href": "pandas_basics.html#exploring-data",
    "title": "Pandas Basics",
    "section": "Exploring Data",
    "text": "Exploring Data\n\n\n# Display the first few rows\ndf.head()\n\n# Display the shape of the DataFrame\nprint(\"Shape:\", df.shape)\n\n# Display summary statistics\ndf.describe()\n\nShape: (3, 3)\n\n\n\n  \n    \n\n\n\n\n\n\nAge\n\n\n\n\ncount\n3.0\n\n\nmean\n30.0\n\n\nstd\n5.0\n\n\nmin\n25.0\n\n\n25%\n27.5\n\n\n50%\n30.0\n\n\n75%\n32.5\n\n\nmax\n35.0"
  },
  {
    "objectID": "pandas_basics.html#selecting-data",
    "href": "pandas_basics.html#selecting-data",
    "title": "Pandas Basics",
    "section": "Selecting Data",
    "text": "Selecting Data\n\n# Selecting a single column\ndf[\"Name\"]\n\n\n\n\n\n\n\n\nName\n\n\n\n\n0\nAlice\n\n\n1\nBob\n\n\n2\nCharlie\n\n\n\n\ndtype: object\n\n\n\n# Selecting multiple columns\ndf[[\"Name\", \"City\"]]\n\n\n  \n    \n\n\n\n\n\n\nName\nCity\n\n\n\n\n0\nAlice\nNew York\n\n\n1\nBob\nLos Angeles\n\n\n2\nCharlie\nChicago\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\n# Selecting rows by index\ndf.iloc[0]\n\n\n\n\n\n\n\n\n0\n\n\n\n\nName\nAlice\n\n\nAge\n25\n\n\nCity\nNew York\n\n\n\n\ndtype: object"
  },
  {
    "objectID": "pandas_basics.html#filtering-data",
    "href": "pandas_basics.html#filtering-data",
    "title": "Pandas Basics",
    "section": "Filtering Data",
    "text": "Filtering Data\n\n# Filtering rows where Age is greater than 25\nfiltered_df = df[df[\"Age\"] &gt; 25]\nfiltered_df\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\n\n\n\n\n1\nBob\n30\nLos Angeles\n\n\n2\nCharlie\n35\nChicago"
  },
  {
    "objectID": "pandas_basics.html#adding-a-new-column",
    "href": "pandas_basics.html#adding-a-new-column",
    "title": "Pandas Basics",
    "section": "Adding a New Column",
    "text": "Adding a New Column\n\n\n# Adding a new column\ndf[\"Salary\"] = [50000, 60000, 70000]\ndf\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\nSalary\n\n\n\n\n0\nAlice\n25\nNew York\n50000\n\n\n1\nBob\n30\nLos Angeles\n60000\n\n\n2\nCharlie\n35\nChicago\n70000\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n    ## Conclusion\n\n    This notebook covers the basic operations of pandas. You can explore more advanced features like merging,\n    joining, and working with time series data in pandas documentation: https://pandas.pydata.org/docs/"
  },
  {
    "objectID": "seaborn_basics.html",
    "href": "seaborn_basics.html",
    "title": "Seaborn Example",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Sample data\ndata = {\n    'Category': ['A', 'B', 'C', 'D'],\n    'Values': [23, 45, 56, 78]\n}\ndf = pd.DataFrame(data)\n\n# Create a barplot\nsns.set(style=\"whitegrid\")  # Optional: Set a clean grid style\nplt.figure(figsize=(8, 6))  # Set the figure size\nsns.barplot(data=df, x='Category', y='Values', palette='viridis')\n\n# Customize the plot\nplt.title(\"Bar Plot Example\", fontsize=16)\nplt.xlabel(\"Category\", fontsize=12)\nplt.ylabel(\"Values\", fontsize=12)\n\n# Show the plot\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(data=df, x='Category', y='Values', palette='viridis')"
  },
  {
    "objectID": "posts/holiday_movies/Holiday_Movie_Blog.html",
    "href": "posts/holiday_movies/Holiday_Movie_Blog.html",
    "title": "Holiday Movies",
    "section": "",
    "text": "import pandas as pd\n\n\nholiday_movies = pd.read_csv(\"https://bcdanl.github.io/data/holiday_movies.csv\")\nholiday_movies\n\n\n  \n    \n\n\n\n\n\n\ntconst\ntitle_type\nprimary_title\nsimple_title\nyear\nruntime_minutes\naverage_rating\nnum_votes\n\n\n\n\n0\ntt0020356\nmovie\nSailor's Holiday\nsailors holiday\n1929\n58.0\n5.4\n55\n\n\n1\ntt0020823\nmovie\nThe Devil's Holiday\nthe devils holiday\n1930\n80.0\n6.0\n242\n\n\n2\ntt0020985\nmovie\nHoliday\nholiday\n1930\n91.0\n6.3\n638\n\n\n3\ntt0021268\nmovie\nHoliday of St. Jorgen\nholiday of st jorgen\n1930\n83.0\n7.4\n256\n\n\n4\ntt0021377\nmovie\nSin Takes a Holiday\nsin takes a holiday\n1930\n81.0\n6.1\n740\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2260\ntt9747440\ntvMovie\nA Christmas Love Story\na christmas love story\n2019\n84.0\n6.9\n1652\n\n\n2261\ntt9747450\ntvMovie\nHoliday for Heroes\nholiday for heroes\n2019\n81.0\n7.0\n1655\n\n\n2262\ntt9802890\ntvMovie\nChristmas Jars\nchristmas jars\n2019\n93.0\n7.3\n914\n\n\n2263\ntt9815084\ntvMovie\nA Very British Christmas\na very british christmas\n2019\n90.0\n5.7\n725\n\n\n2264\ntt9892854\ntvMovie\n#Xmas\nxmas\n2022\n84.0\n5.8\n926\n\n\n\n\n2265 rows × 8 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nholiday_movie_genres = pd.read_csv(\"https://bcdanl.github.io/data/holiday_movie_genres.csv\")\nholiday_movie_genres\n\n\n  \n    \n\n\n\n\n\n\ntconst\ngenres\n\n\n\n\n0\ntt0020356\nComedy\n\n\n1\ntt0020823\nDrama\n\n\n2\ntt0020823\nRomance\n\n\n3\ntt0020985\nComedy\n\n\n4\ntt0020985\nDrama\n\n\n...\n...\n...\n\n\n4526\ntt9815084\nFamily\n\n\n4527\ntt9815084\nRomance\n\n\n4528\ntt9892854\nComedy\n\n\n4529\ntt9892854\nDrama\n\n\n4530\ntt9892854\nRomance\n\n\n\n\n4531 rows × 2 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n#2000s Movies Ordered By Rating\n\nholiday_movies_2000s = holiday_movies[holiday_movies['year']&gt;=2000]\nmovies_2000s_by_rating = holiday_movies_2000s.sort_values('average_rating', ascending = True)\nmovies_2000s_by_rating\n\n\n  \n    \n\n\n\n\n\n\ntconst\ntitle_type\nprimary_title\nsimple_title\nyear\nruntime_minutes\naverage_rating\nnum_votes\n\n\n\n\n2179\ntt8941352\nvideo\nA Grinch Christmas Carol\na grinch christmas carol\n2012\n2.0\n1.0\n41\n\n\n1797\ntt4009460\nmovie\nKirk Cameron's Saving Christmas\nkirk camerons saving christmas\n2014\n79.0\n1.3\n16608\n\n\n854\ntt1242748\nvideo\nJohnson Family Christmas Dinner\njohnson family christmas dinner\n2008\n88.0\n1.5\n127\n\n\n927\ntt13180242\ntvMovie\nA Christmas Call\na christmas call\n2020\nNaN\n1.5\n11\n\n\n1610\ntt2578608\nmovie\nKrampus: The Christmas Devil\nkrampus the christmas devil\n2013\n82.0\n1.6\n1963\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1416\ntt21308838\nvideo\nAunty Donna: Always Room for Christmas Pud\naunty donna always room for christmas pud\n2018\n4.0\n9.3\n24\n\n\n1601\ntt25147828\nmovie\nCheap vs. Expensive Xmas Day\ncheap vs expensive xmas day\n2022\n107.0\n9.5\n14\n\n\n1522\ntt2273141\nvideo\nChristmas Bone Us\nchristmas bone us\n2012\n6.0\n9.8\n10\n\n\n1433\ntt21411946\nmovie\nBringing Back Christmas\nbringing back christmas\n2023\nNaN\n9.9\n20\n\n\n1204\ntt1569470\nvideo\nNLO Spirit of Christmas\nnlo spirit of christmas\n2009\n70.0\n10.0\n18\n\n\n\n\n1789 rows × 8 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n#Top Rated Movies of the 2000s\n\nholiday_movies_2000s = holiday_movies[holiday_movies['year']&gt;=2000]\ntop_movies_2000s = holiday_movies_2000s.loc[holiday_movies_2000s.groupby('year')['average_rating'].idxmax()]\ntop_movies_2000s[['primary_title', 'year', 'average_rating']]\n\n\n  \n    \n\n\n\n\n\n\nprimary_title\nyear\naverage_rating\n\n\n\n\n273\nA Christmas Tree and a Wedding\n2000\n8.3\n\n\n443\nAndy Williams - Best of Christmas\n2001\n8.3\n\n\n531\nSanta Claus Versus the Christmas Vixens\n2002\n9.1\n\n\n508\nAn X-Mas Message from David X. Cohen\n2003\n8.7\n\n\n487\nEastEnders: Christmas Party\n2004\n9.0\n\n\n566\nBrian Setzer: Christmas Extravaganza\n2005\n8.7\n\n\n564\nChristmas and the Civil War\n2006\n9.3\n\n\n1042\nA WowieBozowee Christmas\n2007\n9.1\n\n\n1275\nThe Untold Christmas Story\n2008\n8.1\n\n\n1204\nNLO Spirit of Christmas\n2009\n10.0\n\n\n1306\nSanta Preys for X-mas\n2010\n8.5\n\n\n1388\nBuck Denver Asks... Why Do We Call It Christmas?\n2011\n9.0\n\n\n1522\nChristmas Bone Us\n2012\n9.8\n\n\n1762\nJubilee and Elmer Holiday Adventures: Special ...\n2013\n9.0\n\n\n1987\nChristmas Truce of 1914\n2014\n8.9\n\n\n1929\nPunitive psychiatry: Antichristmas\n2015\n8.9\n\n\n1983\nJoe Pera Helps You Find the Perfect Christmas ...\n2016\n8.3\n\n\n1021\nTBS Wrecked: Christmas Killer\n2017\n8.9\n\n\n1416\nAunty Donna: Always Room for Christmas Pud\n2018\n9.3\n\n\n812\nLast Christmas: Emilia Sings\n2019\n8.9\n\n\n1031\nA Baby Reindeer's First Christmas\n2020\n9.0\n\n\n1100\nThe Business of Christmas 2\n2021\n8.2\n\n\n1601\nCheap vs. Expensive Xmas Day\n2022\n9.5\n\n\n1433\nBringing Back Christmas\n2023\n9.9\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n#Genres of the Top Rated Christmas Movies Throughout the 2000s\n\nmovies_and_genres = pd.merge(top_movies_2000s, holiday_movie_genres, on = ['tconst'], how = 'left')\ngenre_dat = movies_and_genres[['primary_title', 'average_rating', 'genres']]\ngenre_dat.set_index('genres')\n\n\n  \n    \n\n\n\n\n\n\nprimary_title\naverage_rating\n\n\ngenres\n\n\n\n\n\n\nDrama\nA Christmas Tree and a Wedding\n8.3\n\n\nDocumentary\nAndy Williams - Best of Christmas\n8.3\n\n\nComedy\nSanta Claus Versus the Christmas Vixens\n9.1\n\n\nShort\nSanta Claus Versus the Christmas Vixens\n9.1\n\n\nComedy\nAn X-Mas Message from David X. Cohen\n8.7\n\n\nShort\nAn X-Mas Message from David X. Cohen\n8.7\n\n\nComedy\nEastEnders: Christmas Party\n9.0\n\n\nFamily\nEastEnders: Christmas Party\n9.0\n\n\nMusic\nEastEnders: Christmas Party\n9.0\n\n\nMusic\nBrian Setzer: Christmas Extravaganza\n8.7\n\n\nDocumentary\nChristmas and the Civil War\n9.3\n\n\nHistory\nChristmas and the Civil War\n9.3\n\n\nWar\nChristmas and the Civil War\n9.3\n\n\nFamily\nA WowieBozowee Christmas\n9.1\n\n\nDocumentary\nThe Untold Christmas Story\n8.1\n\n\nMusic\nNLO Spirit of Christmas\n10.0\n\n\nAction\nSanta Preys for X-mas\n8.5\n\n\nComedy\nSanta Preys for X-mas\n8.5\n\n\nHorror\nSanta Preys for X-mas\n8.5\n\n\nAdventure\nBuck Denver Asks... Why Do We Call It Christmas?\n9.0\n\n\nComedy\nBuck Denver Asks... Why Do We Call It Christmas?\n9.0\n\n\nFamily\nBuck Denver Asks... Why Do We Call It Christmas?\n9.0\n\n\nComedy\nChristmas Bone Us\n9.8\n\n\nFamily\nChristmas Bone Us\n9.8\n\n\nMystery\nChristmas Bone Us\n9.8\n\n\nAnimation\nJubilee and Elmer Holiday Adventures: Special ...\n9.0\n\n\nShort\nJubilee and Elmer Holiday Adventures: Special ...\n9.0\n\n\nHistory\nChristmas Truce of 1914\n8.9\n\n\nShort\nChristmas Truce of 1914\n8.9\n\n\nWar\nChristmas Truce of 1914\n8.9\n\n\nAnimation\nPunitive psychiatry: Antichristmas\n8.9\n\n\nHorror\nPunitive psychiatry: Antichristmas\n8.9\n\n\nShort\nPunitive psychiatry: Antichristmas\n8.9\n\n\nComedy\nJoe Pera Helps You Find the Perfect Christmas ...\n8.3\n\n\nShort\nTBS Wrecked: Christmas Killer\n8.9\n\n\nComedy\nAunty Donna: Always Room for Christmas Pud\n9.3\n\n\nShort\nAunty Donna: Always Room for Christmas Pud\n9.3\n\n\nDocumentary\nLast Christmas: Emilia Sings\n8.9\n\n\nShort\nLast Christmas: Emilia Sings\n8.9\n\n\nDocumentary\nA Baby Reindeer's First Christmas\n9.0\n\n\nDrama\nThe Business of Christmas 2\n8.2\n\n\nComedy\nCheap vs. Expensive Xmas Day\n9.5\n\n\nFamily\nBringing Back Christmas\n9.9\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n#Most Common Genres for Top Rated Movies in the 2000s\n\ntop_genres = movies_and_genres['genres'].value_counts()\ntop_genres\n\n\n\n\n\n\n\n\ncount\n\n\ngenres\n\n\n\n\n\nComedy\n1025\n\n\nDrama\n828\n\n\nRomance\n737\n\n\nFamily\n707\n\n\nAnimation\n268\n\n\nFantasy\n185\n\n\nAdventure\n117\n\n\nDocumentary\n101\n\n\nShort\n96\n\n\nMusic\n91\n\n\nMusical\n78\n\n\nHorror\n63\n\n\nCrime\n44\n\n\nMystery\n37\n\n\nThriller\n32\n\n\nAction\n31\n\n\nSci-Fi\n14\n\n\nHistory\n13\n\n\nWar\n9\n\n\nWestern\n6\n\n\nBiography\n6\n\n\nSport\n5\n\n\nFilm-Noir\n2\n\n\nTalk-Show\n2\n\n\nNews\n1\n\n\nReality-TV\n1\n\n\n\n\ndtype: int64\n\n\n\nHomeowork 5\n\nmovies_and_genres = pd.merge(holiday_movies, holiday_movie_genres, on = ['tconst'], how = 'left')\nmovies_and_genres = movies_and_genres[['title_type', 'average_rating', 'genres']]\n\n\nmovies_and_genres\n\n\n  \n    \n\n\n\n\n\n\ntitle_type\naverage_rating\ngenres\n\n\n\n\n0\nmovie\n5.4\nComedy\n\n\n1\nmovie\n6.0\nDrama\n\n\n2\nmovie\n6.0\nRomance\n\n\n3\nmovie\n6.3\nComedy\n\n\n4\nmovie\n6.3\nDrama\n\n\n...\n...\n...\n...\n\n\n4526\ntvMovie\n5.7\nFamily\n\n\n4527\ntvMovie\n5.7\nRomance\n\n\n4528\ntvMovie\n5.8\nComedy\n\n\n4529\ntvMovie\n5.8\nDrama\n\n\n4530\ntvMovie\n5.8\nRomance\n\n\n\n\n4531 rows × 3 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nby_genre = pd.DataFrame(holiday_movie_genres.groupby('genres').size().reset_index())\nby_genre.columns = [\"genres\", \"Count\"]\n\n\nby_genre\n\n\n  \n    \n\n\n\n\n\n\ngenres\nCount\n\n\n\n\n0\nAction\n31\n\n\n1\nAdventure\n117\n\n\n2\nAnimation\n268\n\n\n3\nBiography\n6\n\n\n4\nComedy\n1025\n\n\n5\nCrime\n44\n\n\n6\nDocumentary\n101\n\n\n7\nDrama\n828\n\n\n8\nFamily\n707\n\n\n9\nFantasy\n185\n\n\n10\nFilm-Noir\n2\n\n\n11\nHistory\n13\n\n\n12\nHorror\n63\n\n\n13\nMusic\n91\n\n\n14\nMusical\n78\n\n\n15\nMystery\n37\n\n\n16\nNews\n1\n\n\n17\nReality-TV\n1\n\n\n18\nRomance\n737\n\n\n19\nSci-Fi\n14\n\n\n20\nShort\n96\n\n\n21\nSport\n5\n\n\n22\nTalk-Show\n2\n\n\n23\nThriller\n32\n\n\n24\nWar\n9\n\n\n25\nWestern\n6\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nmovies_and_genres = pd.merge(movies_and_genres, by_genre, on = ['genres'])\n\n\nmovies_and_genres\n\n\n  \n    \n\n\n\n\n\n\ntitle_type\naverage_rating\ngenres\nCount\n\n\n\n\n0\nmovie\n5.4\nComedy\n1025\n\n\n1\nmovie\n6.0\nDrama\n828\n\n\n2\nmovie\n6.0\nRomance\n737\n\n\n3\nmovie\n6.3\nComedy\n1025\n\n\n4\nmovie\n6.3\nDrama\n828\n\n\n...\n...\n...\n...\n...\n\n\n4494\ntvMovie\n5.7\nFamily\n707\n\n\n4495\ntvMovie\n5.7\nRomance\n737\n\n\n4496\ntvMovie\n5.8\nComedy\n1025\n\n\n4497\ntvMovie\n5.8\nDrama\n828\n\n\n4498\ntvMovie\n5.8\nRomance\n737\n\n\n\n\n4499 rows × 4 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\ntop_genres = movies_and_genres.groupby('genres')['Count'].sum().nlargest(5).index\ntop_five = movies_and_genres[movies_and_genres['genres'].isin(top_genres)]\ntop_five\n\n\n  \n    \n\n\n\n\n\n\ntitle_type\naverage_rating\ngenres\nCount\n\n\n\n\n0\nmovie\n5.4\nComedy\n1025\n\n\n1\nmovie\n6.0\nDrama\n828\n\n\n2\nmovie\n6.0\nRomance\n737\n\n\n3\nmovie\n6.3\nComedy\n1025\n\n\n4\nmovie\n6.3\nDrama\n828\n\n\n...\n...\n...\n...\n...\n\n\n4494\ntvMovie\n5.7\nFamily\n707\n\n\n4495\ntvMovie\n5.7\nRomance\n737\n\n\n4496\ntvMovie\n5.8\nComedy\n1025\n\n\n4497\ntvMovie\n5.8\nDrama\n828\n\n\n4498\ntvMovie\n5.8\nRomance\n737\n\n\n\n\n3565 rows × 4 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nimport numpy as np\ntop_five['num_log_votes'] = np.log(top_five['Count'])\ntop_five\n\nSettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  top_five['num_log_votes'] = np.log(top_five['Count'])\n\n\n\n  \n    \n\n\n\n\n\n\ntitle_type\naverage_rating\ngenres\nCount\nnum_log_votes\n\n\n\n\n0\nmovie\n5.4\nComedy\n1025\n6.932448\n\n\n1\nmovie\n6.0\nDrama\n828\n6.719013\n\n\n2\nmovie\n6.0\nRomance\n737\n6.602588\n\n\n3\nmovie\n6.3\nComedy\n1025\n6.932448\n\n\n4\nmovie\n6.3\nDrama\n828\n6.719013\n\n\n...\n...\n...\n...\n...\n...\n\n\n4494\ntvMovie\n5.7\nFamily\n707\n6.561031\n\n\n4495\ntvMovie\n5.7\nRomance\n737\n6.602588\n\n\n4496\ntvMovie\n5.8\nComedy\n1025\n6.932448\n\n\n4497\ntvMovie\n5.8\nDrama\n828\n6.719013\n\n\n4498\ntvMovie\n5.8\nRomance\n737\n6.602588\n\n\n\n\n3565 rows × 5 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\n\nsns.boxplot(data = top_five,\n              x = 'num_log_votes',\n              y =  'average_rating',\n              hue = 'title_type')\n\n\n\n\n\n\n\n\nThe rating of Holiday media decreased slightly with more votes. TV Movies appeared to have the most consistent decreases in ratings with more votes."
  },
  {
    "objectID": "posts/spotify/Spotify_Blog.html",
    "href": "posts/spotify/Spotify_Blog.html",
    "title": "Spotify",
    "section": "",
    "text": "Part 4. Jupyter Notebook Blogging\nWrite a blog post about your favorite artist(s) in the spotify DataFrame using Jupyter Notebook, and add it to your online blog. In your blog post, utilize counting, sorting, indexing, and filtering methods.\n\nimport pandas as pd\n\n\nspotify = pd.read_csv('https://bcdanl.github.io/data/spotify_all.csv')\nspotify\n\n\n  \n    \n\n\n\n\n\n\npid\nplaylist_name\npos\nartist_name\ntrack_name\nduration_ms\nalbum_name\n\n\n\n\n0\n0\nThrowbacks\n0\nMissy Elliott\nLose Control (feat. Ciara & Fat Man Scoop)\n226863\nThe Cookbook\n\n\n1\n0\nThrowbacks\n1\nBritney Spears\nToxic\n198800\nIn The Zone\n\n\n2\n0\nThrowbacks\n2\nBeyoncé\nCrazy In Love\n235933\nDangerously In Love (Alben für die Ewigkeit)\n\n\n3\n0\nThrowbacks\n3\nJustin Timberlake\nRock Your Body\n267266\nJustified\n\n\n4\n0\nThrowbacks\n4\nShaggy\nIt Wasn't Me\n227600\nHot Shot\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n198000\n999998\n✝️\n6\nChris Tomlin\nWaterfall\n209573\nLove Ran Red\n\n\n198001\n999998\n✝️\n7\nChris Tomlin\nThe Roar\n220106\nLove Ran Red\n\n\n198002\n999998\n✝️\n8\nCrowder\nLift Your Head Weary Sinner (Chains)\n224666\nNeon Steeple\n\n\n198003\n999998\n✝️\n9\nChris Tomlin\nWe Fall Down\n280960\nHow Great Is Our God: The Essential Collection\n\n\n198004\n999998\n✝️\n10\nCaleb and Kelsey\n10,000 Reasons / What a Beautiful Name\n178189\n10,000 Reasons / What a Beautiful Name\n\n\n\n\n198005 rows × 7 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\nI really enjoy the spotify playlist “Throwbacks”.\n\nthrowbacks = spotify['playlist_name'] == \"Throwbacks\"\nthrowbacks_df = spotify[throwbacks]\nthrowbacks_df\n\n\n  \n    \n\n\n\n\n\n\npid\nplaylist_name\npos\nartist_name\ntrack_name\nduration_ms\nalbum_name\n\n\n\n\n0\n0\nThrowbacks\n0\nMissy Elliott\nLose Control (feat. Ciara & Fat Man Scoop)\n226863\nThe Cookbook\n\n\n1\n0\nThrowbacks\n1\nBritney Spears\nToxic\n198800\nIn The Zone\n\n\n2\n0\nThrowbacks\n2\nBeyoncé\nCrazy In Love\n235933\nDangerously In Love (Alben für die Ewigkeit)\n\n\n3\n0\nThrowbacks\n3\nJustin Timberlake\nRock Your Body\n267266\nJustified\n\n\n4\n0\nThrowbacks\n4\nShaggy\nIt Wasn't Me\n227600\nHot Shot\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n186699\n999823\nThrowbacks\n5\nNelly Furtado\nPromiscuous\n242293\nLoose\n\n\n186700\n999823\nThrowbacks\n6\nUsher\nDJ Got Us Fallin' In Love\n220800\nRaymond v Raymond (Deluxe Edition)\n\n\n186701\n999823\nThrowbacks\n7\nIyaz\nReplay\n182306\nReplay\n\n\n186702\n999823\nThrowbacks\n8\nJay Sean\nDown\n212506\nAll Or Nothing\n\n\n186703\n999823\nThrowbacks\n9\nFar East Movement\nLike A G6\n216893\nFree Wired\n\n\n\n\n627 rows × 7 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nthrowbacks_df['artist_name'].nunique()\n\n223\n\n\nThere is a total of 223 different artists in this playlist, including one of my favorite artists, Britney Spears.\n\nby_artist = throwbacks_df.set_index(keys = \"artist_name\")\nby_artist\n\n\n  \n    \n\n\n\n\n\n\npid\nplaylist_name\npos\ntrack_name\nduration_ms\nalbum_name\n\n\nartist_name\n\n\n\n\n\n\n\n\n\n\nMissy Elliott\n0\nThrowbacks\n0\nLose Control (feat. Ciara & Fat Man Scoop)\n226863\nThe Cookbook\n\n\nBritney Spears\n0\nThrowbacks\n1\nToxic\n198800\nIn The Zone\n\n\nBeyoncé\n0\nThrowbacks\n2\nCrazy In Love\n235933\nDangerously In Love (Alben für die Ewigkeit)\n\n\nJustin Timberlake\n0\nThrowbacks\n3\nRock Your Body\n267266\nJustified\n\n\nShaggy\n0\nThrowbacks\n4\nIt Wasn't Me\n227600\nHot Shot\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\nNelly Furtado\n999823\nThrowbacks\n5\nPromiscuous\n242293\nLoose\n\n\nUsher\n999823\nThrowbacks\n6\nDJ Got Us Fallin' In Love\n220800\nRaymond v Raymond (Deluxe Edition)\n\n\nIyaz\n999823\nThrowbacks\n7\nReplay\n182306\nReplay\n\n\nJay Sean\n999823\nThrowbacks\n8\nDown\n212506\nAll Or Nothing\n\n\nFar East Movement\n999823\nThrowbacks\n9\nLike A G6\n216893\nFree Wired\n\n\n\n\n627 rows × 6 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nbritney = throwbacks_df['artist_name'] == \"Britney Spears\"\nbritney_df = throwbacks_df[britney]\nbritney_df\n\n\n  \n    \n\n\n\n\n\n\npid\nplaylist_name\npos\nartist_name\ntrack_name\nduration_ms\nalbum_name\n\n\n\n\n1\n0\nThrowbacks\n1\nBritney Spears\nToxic\n198800\nIn The Zone\n\n\n24216\n380\nThrowbacks\n1\nBritney Spears\nCircus\n192360\nCircus (Deluxe Version)\n\n\n24245\n380\nThrowbacks\n30\nBritney Spears\n3\n213173\nThe Singles Collection\n\n\n24340\n380\nThrowbacks\n125\nBritney Spears\nWomanizer\n224400\nCircus (Deluxe Version)\n\n\n48261\n717\nThrowbacks\n51\nBritney Spears\nToxic\n198800\nIn The Zone\n\n\n48262\n717\nThrowbacks\n52\nBritney Spears\n...Baby One More Time\n211066\n...Baby One More Time (Digital Deluxe Version)\n\n\n60323\n895\nThrowbacks\n121\nBritney Spears\nStronger\n203000\nOops!... I Did It Again\n\n\n60324\n895\nThrowbacks\n122\nBritney Spears\nLucky\n206226\nOops!... I Did It Again\n\n\n83553\n1247\nThrowbacks\n3\nBritney Spears\nOops!...I Did It Again\n211160\nOops!... I Did It Again\n\n\n83554\n1247\nThrowbacks\n4\nBritney Spears\nToxic\n198800\nIn The Zone\n\n\n83555\n1247\nThrowbacks\n5\nBritney Spears\nI'm a Slave 4 U\n203600\nBritney (Digital Deluxe Version)\n\n\n83556\n1247\nThrowbacks\n6\nBritney Spears\nPiece of Me\n212106\nBlackout\n\n\n83615\n1247\nThrowbacks\n65\nBritney Spears\nLucky\n206226\nOops!... I Did It Again\n\n\n83644\n1247\nThrowbacks\n94\nBritney Spears\nI'm Not a Girl, Not Yet a Woman\n231066\nBritney (Digital Deluxe Version)\n\n\n83645\n1247\nThrowbacks\n95\nBritney Spears\nGimme More\n251240\nBlackout\n\n\n135830\n999022\nThrowbacks\n64\nBritney Spears\nCircus\n192360\nCircus (Deluxe Version)\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nbritney_df['track_name'].count()\n\n16\n\n\nShe has 16 different songs in the playlist:\n\nbritney_df['track_name']\n\n\n\n\n\n\n\n\ntrack_name\n\n\n\n\n1\nToxic\n\n\n24216\nCircus\n\n\n24245\n3\n\n\n24340\nWomanizer\n\n\n48261\nToxic\n\n\n48262\n...Baby One More Time\n\n\n60323\nStronger\n\n\n60324\nLucky\n\n\n83553\nOops!...I Did It Again\n\n\n83554\nToxic\n\n\n83555\nI'm a Slave 4 U\n\n\n83556\nPiece of Me\n\n\n83615\nLucky\n\n\n83644\nI'm Not a Girl, Not Yet a Woman\n\n\n83645\nGimme More\n\n\n135830\nCircus\n\n\n\n\ndtype: object\n\n\n\nsong_length = britney_df['duration_ms'].sort_values(ascending=False)\nsong_length\nsong_length_min = song_length/60000\nsong_length_min\n\n\n\n\n\n\n\n\nduration_ms\n\n\n\n\n83645\n4.187333\n\n\n83644\n3.851100\n\n\n24340\n3.740000\n\n\n24245\n3.552883\n\n\n83556\n3.535100\n\n\n83553\n3.519333\n\n\n48262\n3.517767\n\n\n60324\n3.437100\n\n\n83615\n3.437100\n\n\n83555\n3.393333\n\n\n60323\n3.383333\n\n\n1\n3.313333\n\n\n48261\n3.313333\n\n\n83554\n3.313333\n\n\n24216\n3.206000\n\n\n135830\n3.206000\n\n\n\n\ndtype: float64\n\n\nHer longest song is 4.187 minutes, while her shortest song is 3.206 minutes.\n\nsong_length_min.sum()\n\n55.90638333333333\n\n\nShe makes up a total of 55.906 minutes of the playlist “Throwbacks”.\n\n\nHomework 5\n\nart_track_df = pd.DataFrame(spotify.groupby('artist_name')['track_name'].size())\n\n\ntop_ten = art_track_df.sort_values(\"track_name\", ascending = False).head(10)\ntop_ten = top_ten.reset_index()\n\n\nspotify_top_ten = spotify[spotify['artist_name'].isin(top_ten['artist_name'])]\n\n\nspotify_top_ten\n\n\n  \n    \n\n\n\n\n\n\npid\nplaylist_name\npos\nartist_name\ntrack_name\nduration_ms\nalbum_name\n\n\n\n\n320\n5\nWedding\n22\nRihanna\nWe Found Love\n215226\nTalk That Talk\n\n\n333\n5\nWedding\n35\nEd Sheeran\nThinking Out Loud\n281560\nx\n\n\n522\n10\nabby\n8\nDrake\nPortland\n236614\nMore Life\n\n\n540\n10\nabby\n26\nKendrick Lamar\nm.A.A.d city\n350120\ngood kid, m.A.A.d city\n\n\n544\n10\nabby\n30\nDrake\nPreach\n236973\nIf You're Reading This It's Too Late\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n197714\n999992\nGB\n100\nRihanna\nBitch Better Have My Money\n219305\nBitch Better Have My Money\n\n\n197754\n999994\nSlow Songs\n3\nThe Weeknd\nEarned It (Fifty Shades Of Grey)\n277706\nBeauty Behind The Madness\n\n\n197768\n999994\nSlow Songs\n17\nEd Sheeran\nThinking Out Loud\n281560\nx\n\n\n197802\n999994\nSlow Songs\n51\nThe Weeknd\nI Feel It Coming\n269186\nStarboy\n\n\n197975\n999997\nSex\n5\nThe Weeknd\nEarned It (Fifty Shades Of Grey)\n277706\nBeauty Behind The Madness\n\n\n\n\n10276 rows × 7 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\n\nsns.countplot(data = spotify_top_ten,\n              y =  'artist_name')\n\n\n\n\n\n\n\n\nOut of the top ten artists, Drake had the most songs my a significant margin. Other prominent artists included Kanye West, Kendrick Lamar, and Rihanna."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code with no space in the folder name.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/starwars/starwars_df.html",
    "href": "posts/starwars/starwars_df.html",
    "title": "Starwars",
    "section": "",
    "text": "Let’s analyze the starwars data:\nstarwars &lt;- read_csv(\"https://bcdanl.github.io/data/starwars.csv\")"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "href": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "title": "Starwars",
    "section": "Variable Description for starwars data.frame",
    "text": "Variable Description for starwars data.frame\nThe following describes the variables in the starwars data.frame.\n\nfilms List of films the character appeared in\nname Name of the character\nspecies Name of species\nheight Height (cm)\nmass Weight (kg)\nhair_color, skin_color, eye_color Hair, skin, and eye colors\nbirth_year Year born (BBY = Before Battle of Yavin)\nsex The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).\ngender The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).\nhomeworld Name of homeworld"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#human-vs.-droid",
    "href": "posts/starwars/starwars_df.html#human-vs.-droid",
    "title": "Starwars",
    "section": "Human vs. Droid",
    "text": "Human vs. Droid\n\nggplot(data = \n         starwars %&gt;% \n         filter(species %in% c(\"Human\", \"Droid\"))) +\n  geom_boxplot(aes(x = species, y = mass, \n                   fill = species),\n               show.legend = FALSE)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sophia Stang",
    "section": "",
    "text": "Sophia Stang majors in Biology and minors in Data Analytics and the Honors Program at SUNY Geneseo. When not working on research and data analytics, Sophia enjoys spending time practicing the arts and reading."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Sophia Stang",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo | Geneseo, NY  B.S. in Biology | Aug 2022 - May 2026  Minor in Data Analytics and College Honors Program"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Sophia Stang",
    "section": "Experience",
    "text": "Experience\nSUNY Geneseo CIT HelpDesk Manager | Native Bee Ecology Directed Study | May 2024 - Aug 2024"
  },
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Insightful Analytics",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nSustainability in Industries Project\n\n\n\n\n\n\n\n\nMay 16, 2025\n\n\nSophia Stang\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nHoliday Movies\n\n\n\n\n\n\n\n\nApr 8, 2025\n\n\nSophia Stang\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nSpotify\n\n\n\n\n\n\n\n\nMar 3, 2025\n\n\nSophia Stang\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\n\n\nMar 2, 2025\n\n\nHarlow Malloc\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\nFeb 27, 2025\n\n\nTristan O’Malley\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\nJan 22, 2025\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nStarwars\n\n\n\n\n\n\n\n\nJan 22, 2025\n\n\nYour Name\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\n\n\nJan 22, 2025\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "myblog/posts/post-with-code/index.html",
    "href": "myblog/posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "myblog/index.html",
    "href": "myblog/index.html",
    "title": "myblog",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 2, 2025\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nFeb 27, 2025\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/project/Sustainability_in_Industries_Project.html",
    "href": "posts/project/Sustainability_in_Industries_Project.html",
    "title": "Sustainability in Industries Project",
    "section": "",
    "text": "Sustainability in business is related to both environmental and societal effects of the company. Reinforcing sustainability initiatives is helpful in reducing climate change, income inequality, natural resource depletion, and many more important issues in our current world. In addition to this, sustainability is beneficial to the company itself, causing it to outcompete other less sustainable organizations. The benefits of being a sustainable business include protecting your brand, creating a purpose-driven company, and partaking in the growing sustainability market (Chladek, 2019).\n##Statement of the Problem: Clearly articulate the specific problem or issue the project will address.\nThis project aims to determine which sectors and industries are most harmful to the environment and determine the connection between environmental safety and market growth. The project also will test whether environmental safety is related to the public controversy level of the industry.\n\n\n\nSet Up: Import packages and data\n\nimport pandas as pd\nurl_2024 = \"https://bcdanl.github.io/data/esg_proj_2024_data.csv\"\nesg_proj_2024_data = pd.read_csv(url_2024)\nurl_2025 = \"https://bcdanl.github.io/data/esg_proj_2025.csv\"\nesg_proj_2025 = pd.read_csv(url_2025)\nesg_2025_dropd = esg_proj_2025.drop_duplicates(subset = [\"Name\"])\nesg_2024_2025 = pd.merge(esg_2025_dropd, esg_proj_2024_data,on = 'Name', how = 'inner')\nurl = \"https://bcdanl.github.io/data/stock_history_2023.csv\"\nstock_history_2023 = pd.read_csv(url)\nesg_2025 = pd.read_csv(\"danl_210_stang_sophia_ESG.csv\")\nstock = pd.read_csv('danl_210_stang_sophia_stock.csv')\n\n\nstock = stock.drop(columns = \"Unnamed: 0\")\n\n\nstock\n\n\n  \n    \n\n\n\n\n\n\nInfo\nDate\nOpen\nHigh\nLow\nClose\nAdj_close\nSymbol\n\n\n\n\n0\nMar 31, 2025 116.36 117.73 113.76 116.98 116.7...\nMar 31, 2025\n116.36\n117.73\n113.76\n116.98\n116.73\nA\n\n\n1\nMar 31, 2025 29.74 30.63 28.80 30.50 30.50 4,9...\nMar 31, 2025\n29.74\n30.63\n28.80\n30.50\n30.50\nAA\n\n\n2\nMar 31, 2025 10.41 10.68 10.06 10.55 10.55 66,...\nMar 31, 2025\n10.41\n10.68\n10.06\n10.55\n10.55\nAAL\n\n\n3\nMar 31, 2025 38.36 39.65 38.25 39.21 38.91 2,3...\nMar 31, 2025\n38.36\n39.65\n38.25\n39.21\n38.91\nAAP\n\n\n4\nMar 31, 2025 217.01 225.62 216.23 222.13 222.1...\nMar 31, 2025\n217.01\n225.62\n216.23\n222.13\n222.13\nAAPL\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n620\nMar 31, 2025 118.64 120.11 116.52 119.46 119.4...\nMar 31, 2025\n118.64\n120.11\n116.52\n119.46\n119.46\nXYL\n\n\n621\nMar 31, 2025 154.18 158.14 153.61 157.36 157.3...\nMar 31, 2025\n154.18\n158.14\n153.61\n157.36\n157.36\nYUM\n\n\n622\nMar 31, 2025 67.54 68.90 66.13 68.56 68.56 2,3...\nMar 31, 2025\n67.54\n68.90\n66.13\n68.56\n68.56\nZ\n\n\n623\nMar 31, 2025 111.37 113.64 111.37 113.18 113.1...\nMar 31, 2025\n111.37\n113.64\n111.37\n113.18\n113.18\nZBH\n\n\n624\nMar 31, 2025 163.12 164.90 161.58 164.65 164.1...\nMar 31, 2025\n163.12\n164.90\n161.58\n164.65\n164.10\nZTS\n\n\n\n\n625 rows × 8 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nesg_2025 = esg_2025.drop(columns = [\"Unnamed: 0\"])\n\n\nesg_2025\n\n\n  \n    \n\n\n\n\n\n\nYear\nSymbol\nName\nSector\nIndustry\nCountry\nMarket_Cap\nIPO_Year\nTotal_ESG\nEnvironmental\nSocial\nGovernance\nControversy\n\n\n\n\n0\n2025\nA\nAgilent Technologies Inc. Common Stock\nIndustrials\nBiotechnology: Laboratory Analytical Instruments\nUnited States\n3.391867e+10\n1999.0\n13.6\n1.1\n6.4\n6.1\n2.0\n\n\n1\n2025\nAA\nAlcoa Corporation Common Stock\nIndustrials\nAluminum\nUnited States\n8.279121e+09\n2016.0\n24.0\n13.8\n5.9\n4.3\n3.0\n\n\n2\n2025\nAAL\nAmerican Airlines Group Inc. Common Stock\nConsumer Discretionary\nAir Freight/Delivery Services\nUnited States\n7.325392e+09\nNaN\n26.4\n9.9\n11.6\n4.8\n2.0\n\n\n3\n2025\nAAP\nAdvance Auto Parts Inc.\nConsumer Discretionary\nAuto & Home Supply Stores\nUnited States\n2.413841e+09\nNaN\n11.5\n0.1\n8.3\n3.1\n2.0\n\n\n4\n2025\nAAPL\nApple Inc. Common Stock\nTechnology\nComputer Manufacturing\nUnited States\n3.362691e+12\n1980.0\n17.2\n0.5\n7.4\n9.4\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n620\n2025\nXYL\nXylem Inc. Common Stock New\nIndustrials\nFluid Controls\nUnited States\n2.965650e+10\n2011.0\n18.1\n4.3\n8.7\n5.2\n1.0\n\n\n621\n2025\nYUM\nYum! Brands Inc.\nConsumer Discretionary\nRestaurants\nUnited States\n4.400042e+10\nNaN\n20.1\n4.5\n11.4\n4.1\n2.0\n\n\n622\n2025\nZ\nZillow Group Inc. Class C Capital Stock\nConsumer Discretionary\nBusiness Services\nUnited States\n1.706396e+10\nNaN\n22.2\n1.2\n11.5\n9.5\n2.0\n\n\n623\n2025\nZBH\nZimmer Biomet Holdings Inc. Common Stock\nHealth Care\nIndustrial Specialties\nUnited States\n2.232493e+10\nNaN\n26.0\n3.6\n14.5\n7.9\n2.0\n\n\n624\n2025\nZTS\nZoetis Inc. Class A Common Stock\nHealth Care\nBiotechnology: Pharmaceutical Preparations\nUnited States\n7.389462e+10\n2013.0\n18.8\n3.2\n6.8\n8.7\n2.0\n\n\n\n\n625 rows × 13 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\nMerge All ESG Data\n\nall_esg = pd.merge(esg_proj_2024_data, esg_2025, on = [\"Year\", \"Symbol\", \"Name\", \"Sector\", \"Industry\", \"Country\", \"Market_Cap\", \"IPO_Year\", \"Total_ESG\", \"Environmental\", \"Social\", \"Governance\", \"Controversy\"], how = \"outer\")\n\n\nall_esg\n\n\n  \n    \n\n\n\n\n\n\nYear\nSymbol\nName\nSector\nIndustry\nCountry\nMarket_Cap\nIPO_Year\nTotal_ESG\nEnvironmental\nSocial\nGovernance\nControversy\n\n\n\n\n0\n2024\nA\nAgilent Technologies Inc. Common Stock\nIndustrials\nBiotechnology: Laboratory Analytical Instruments\nUnited States\n4.036543e+10\n1999.0\n13.6\n1.1\n6.4\n6.1\n2.0\n\n\n1\n2024\nAA\nAlcoa Corporation Common Stock\nIndustrials\nAluminum\nUnited States\n6.622136e+09\n2016.0\n24.0\n13.8\n5.9\n4.3\n3.0\n\n\n2\n2024\nAAL\nAmerican Airlines Group Inc. Common Stock\nConsumer Discretionary\nAir Freight/Delivery Services\nUnited States\n9.088025e+09\nNaN\n26.4\n9.9\n11.6\n4.8\n2.0\n\n\n3\n2024\nAAP\nAdvance Auto Parts Inc.\nConsumer Discretionary\nAuto & Home Supply Stores\nUnited States\n4.474665e+09\nNaN\n11.5\n0.1\n8.3\n3.1\n2.0\n\n\n4\n2024\nAAPL\nApple Inc. Common Stock\nTechnology\nComputer Manufacturing\nUnited States\n2.614310e+12\n1980.0\n17.2\n0.5\n7.4\n9.4\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1245\n2025\nXYL\nXylem Inc. Common Stock New\nIndustrials\nFluid Controls\nUnited States\n2.965650e+10\n2011.0\n18.1\n4.3\n8.7\n5.2\n1.0\n\n\n1246\n2025\nYUM\nYum! Brands Inc.\nConsumer Discretionary\nRestaurants\nUnited States\n4.400042e+10\nNaN\n20.1\n4.5\n11.4\n4.1\n2.0\n\n\n1247\n2025\nZ\nZillow Group Inc. Class C Capital Stock\nConsumer Discretionary\nBusiness Services\nUnited States\n1.706396e+10\nNaN\n22.2\n1.2\n11.5\n9.5\n2.0\n\n\n1248\n2025\nZBH\nZimmer Biomet Holdings Inc. Common Stock\nHealth Care\nIndustrial Specialties\nUnited States\n2.232493e+10\nNaN\n26.0\n3.6\n14.5\n7.9\n2.0\n\n\n1249\n2025\nZTS\nZoetis Inc. Class A Common Stock\nHealth Care\nBiotechnology: Pharmaceutical Preparations\nUnited States\n7.389462e+10\n2013.0\n18.8\n3.2\n6.8\n8.7\n2.0\n\n\n\n\n1250 rows × 13 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nall_esg.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1250 entries, 0 to 1249\nData columns (total 13 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   Year           1250 non-null   int64  \n 1   Symbol         1250 non-null   object \n 2   Name           1250 non-null   object \n 3   Sector         1250 non-null   object \n 4   Industry       1250 non-null   object \n 5   Country        1246 non-null   object \n 6   Market_Cap     1250 non-null   float64\n 7   IPO_Year       402 non-null    float64\n 8   Total_ESG      1250 non-null   float64\n 9   Environmental  1204 non-null   float64\n 10  Social         1204 non-null   float64\n 11  Governance     1204 non-null   float64\n 12  Controversy    1146 non-null   float64\ndtypes: float64(7), int64(1), object(5)\nmemory usage: 127.1+ KB\n\n\n\nsectors = all_esg.groupby('Sector')[\"Total_ESG\"].mean()\n\n\nsectors_df = pd.DataFrame(sectors)\nsectors_df.sort_values(\"Total_ESG\", ascending = False)\n\n\n  \n    \n\n\n\n\n\n\nTotal_ESG\n\n\nSector\n\n\n\n\n\nEnergy\n32.788000\n\n\nUtilities\n26.547619\n\n\nConsumer Staples\n26.359091\n\n\nIndustrials\n23.678947\n\n\nHealth Care\n22.815789\n\n\nFinance\n21.754737\n\n\nBasic Materials\n21.750000\n\n\nTelecommunications\n20.406250\n\n\nConsumer Discretionary\n19.588158\n\n\nTechnology\n18.129577\n\n\nReal Estate\n13.880952\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\nenergy = all_esg['Sector'] == \"Energy\"\nenergy = all_esg[energy]\nindustry_esg = energy.groupby(\"Industry\")[\"Total_ESG\"].mean()\nindustry_esg\n\n\n\n\n\n\n\n\nTotal_ESG\n\n\nIndustry\n\n\n\n\n\nIntegrated oil Companies\n34.788889\n\n\nNatural Gas Distribution\n21.100000\n\n\nOil & Gas Production\n33.815385\n\n\nOilfield Services/Equipment\n22.950000\n\n\n\n\ndtype: float64\n\n\n\nindustry_market_cap = energy.groupby(\"Industry\")[\"Market_Cap\"].mean()\nindustry_market_cap\n\n\n\n\n\n\n\n\nMarket_Cap\n\n\nIndustry\n\n\n\n\n\nIntegrated oil Companies\n1.372203e+11\n\n\nNatural Gas Distribution\n8.637729e+10\n\n\nOil & Gas Production\n2.829162e+10\n\n\nOilfield Services/Equipment\n4.644217e+10\n\n\n\n\ndtype: float64\n\n\n\nControv_env = all_esg.groupby(\"Controversy\")[\"Environmental\"].mean()\nControv_env\n\n\n\n\n\n\n\n\nEnvironmental\n\n\nControversy\n\n\n\n\n\n0.0\n5.560000\n\n\n1.0\n5.136076\n\n\n2.0\n5.857762\n\n\n3.0\n6.397030\n\n\n4.0\n6.778571\n\n\n5.0\n9.600000\n\n\n\n\ndtype: float64\n\n\n\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\nWhat sectors have the highest ESG scores and why might that be? How does that change across years?\n\nsns.boxplot(data = all_esg,\n            y = 'Sector',\n            x = 'Total_ESG',\n            hue = 'Year')\n\n\n\n\n\n\n\n\n\nenergy = all_esg['Sector'] == \"Energy\"\nenergy = all_esg[energy]\n\nWhat energy industries in the Energy Sector have the worst ESG scores?\n\nsns.boxplot(data = energy,\n            y = 'Industry',\n            x = 'Total_ESG',\n            hue = 'Year')\n\n\n\n\n\n\n\n\nWhat are the market capitalizations of energy industries?\n\nsns.boxplot(data = energy,\n            y = 'Industry',\n            x = 'Market_Cap',\n            hue = 'Year')\n\n\n\n\n\n\n\n\nWhat is the relationship between ESG scores and market growth?\n\nsns.lineplot(data = all_esg,\n            x = 'Total_ESG',\n            y = 'Market_Cap')\n\n\n\n\n\n\n\n\nIs there a clear relationship between environmental scores and controversy scores?\n\nsns.boxplot(data = all_esg,\n            x = 'Controversy',\n            y = 'Environmental')"
  },
  {
    "objectID": "posts/project/Sustainability_in_Industries_Project.html#background-provide-context-for-the-research-questions-explaining-why-they-are-significant-relevant-or-interesting.",
    "href": "posts/project/Sustainability_in_Industries_Project.html#background-provide-context-for-the-research-questions-explaining-why-they-are-significant-relevant-or-interesting.",
    "title": "Sustainability in Industries Project",
    "section": "",
    "text": "Sustainability in business is related to both environmental and societal effects of the company. Reinforcing sustainability initiatives is helpful in reducing climate change, income inequality, natural resource depletion, and many more important issues in our current world. In addition to this, sustainability is beneficial to the company itself, causing it to outcompete other less sustainable organizations. The benefits of being a sustainable business include protecting your brand, creating a purpose-driven company, and partaking in the growing sustainability market (Chladek, 2019).\n##Statement of the Problem: Clearly articulate the specific problem or issue the project will address.\nThis project aims to determine which sectors and industries are most harmful to the environment and determine the connection between environmental safety and market growth. The project also will test whether environmental safety is related to the public controversy level of the industry."
  },
  {
    "objectID": "posts/project/Sustainability_in_Industries_Project.html#descriptive-statistics",
    "href": "posts/project/Sustainability_in_Industries_Project.html#descriptive-statistics",
    "title": "Sustainability in Industries Project",
    "section": "",
    "text": "Set Up: Import packages and data\n\nimport pandas as pd\nurl_2024 = \"https://bcdanl.github.io/data/esg_proj_2024_data.csv\"\nesg_proj_2024_data = pd.read_csv(url_2024)\nurl_2025 = \"https://bcdanl.github.io/data/esg_proj_2025.csv\"\nesg_proj_2025 = pd.read_csv(url_2025)\nesg_2025_dropd = esg_proj_2025.drop_duplicates(subset = [\"Name\"])\nesg_2024_2025 = pd.merge(esg_2025_dropd, esg_proj_2024_data,on = 'Name', how = 'inner')\nurl = \"https://bcdanl.github.io/data/stock_history_2023.csv\"\nstock_history_2023 = pd.read_csv(url)\nesg_2025 = pd.read_csv(\"danl_210_stang_sophia_ESG.csv\")\nstock = pd.read_csv('danl_210_stang_sophia_stock.csv')\n\n\nstock = stock.drop(columns = \"Unnamed: 0\")\n\n\nstock\n\n\n  \n    \n\n\n\n\n\n\nInfo\nDate\nOpen\nHigh\nLow\nClose\nAdj_close\nSymbol\n\n\n\n\n0\nMar 31, 2025 116.36 117.73 113.76 116.98 116.7...\nMar 31, 2025\n116.36\n117.73\n113.76\n116.98\n116.73\nA\n\n\n1\nMar 31, 2025 29.74 30.63 28.80 30.50 30.50 4,9...\nMar 31, 2025\n29.74\n30.63\n28.80\n30.50\n30.50\nAA\n\n\n2\nMar 31, 2025 10.41 10.68 10.06 10.55 10.55 66,...\nMar 31, 2025\n10.41\n10.68\n10.06\n10.55\n10.55\nAAL\n\n\n3\nMar 31, 2025 38.36 39.65 38.25 39.21 38.91 2,3...\nMar 31, 2025\n38.36\n39.65\n38.25\n39.21\n38.91\nAAP\n\n\n4\nMar 31, 2025 217.01 225.62 216.23 222.13 222.1...\nMar 31, 2025\n217.01\n225.62\n216.23\n222.13\n222.13\nAAPL\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n620\nMar 31, 2025 118.64 120.11 116.52 119.46 119.4...\nMar 31, 2025\n118.64\n120.11\n116.52\n119.46\n119.46\nXYL\n\n\n621\nMar 31, 2025 154.18 158.14 153.61 157.36 157.3...\nMar 31, 2025\n154.18\n158.14\n153.61\n157.36\n157.36\nYUM\n\n\n622\nMar 31, 2025 67.54 68.90 66.13 68.56 68.56 2,3...\nMar 31, 2025\n67.54\n68.90\n66.13\n68.56\n68.56\nZ\n\n\n623\nMar 31, 2025 111.37 113.64 111.37 113.18 113.1...\nMar 31, 2025\n111.37\n113.64\n111.37\n113.18\n113.18\nZBH\n\n\n624\nMar 31, 2025 163.12 164.90 161.58 164.65 164.1...\nMar 31, 2025\n163.12\n164.90\n161.58\n164.65\n164.10\nZTS\n\n\n\n\n625 rows × 8 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nesg_2025 = esg_2025.drop(columns = [\"Unnamed: 0\"])\n\n\nesg_2025\n\n\n  \n    \n\n\n\n\n\n\nYear\nSymbol\nName\nSector\nIndustry\nCountry\nMarket_Cap\nIPO_Year\nTotal_ESG\nEnvironmental\nSocial\nGovernance\nControversy\n\n\n\n\n0\n2025\nA\nAgilent Technologies Inc. Common Stock\nIndustrials\nBiotechnology: Laboratory Analytical Instruments\nUnited States\n3.391867e+10\n1999.0\n13.6\n1.1\n6.4\n6.1\n2.0\n\n\n1\n2025\nAA\nAlcoa Corporation Common Stock\nIndustrials\nAluminum\nUnited States\n8.279121e+09\n2016.0\n24.0\n13.8\n5.9\n4.3\n3.0\n\n\n2\n2025\nAAL\nAmerican Airlines Group Inc. Common Stock\nConsumer Discretionary\nAir Freight/Delivery Services\nUnited States\n7.325392e+09\nNaN\n26.4\n9.9\n11.6\n4.8\n2.0\n\n\n3\n2025\nAAP\nAdvance Auto Parts Inc.\nConsumer Discretionary\nAuto & Home Supply Stores\nUnited States\n2.413841e+09\nNaN\n11.5\n0.1\n8.3\n3.1\n2.0\n\n\n4\n2025\nAAPL\nApple Inc. Common Stock\nTechnology\nComputer Manufacturing\nUnited States\n3.362691e+12\n1980.0\n17.2\n0.5\n7.4\n9.4\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n620\n2025\nXYL\nXylem Inc. Common Stock New\nIndustrials\nFluid Controls\nUnited States\n2.965650e+10\n2011.0\n18.1\n4.3\n8.7\n5.2\n1.0\n\n\n621\n2025\nYUM\nYum! Brands Inc.\nConsumer Discretionary\nRestaurants\nUnited States\n4.400042e+10\nNaN\n20.1\n4.5\n11.4\n4.1\n2.0\n\n\n622\n2025\nZ\nZillow Group Inc. Class C Capital Stock\nConsumer Discretionary\nBusiness Services\nUnited States\n1.706396e+10\nNaN\n22.2\n1.2\n11.5\n9.5\n2.0\n\n\n623\n2025\nZBH\nZimmer Biomet Holdings Inc. Common Stock\nHealth Care\nIndustrial Specialties\nUnited States\n2.232493e+10\nNaN\n26.0\n3.6\n14.5\n7.9\n2.0\n\n\n624\n2025\nZTS\nZoetis Inc. Class A Common Stock\nHealth Care\nBiotechnology: Pharmaceutical Preparations\nUnited States\n7.389462e+10\n2013.0\n18.8\n3.2\n6.8\n8.7\n2.0\n\n\n\n\n625 rows × 13 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\nMerge All ESG Data\n\nall_esg = pd.merge(esg_proj_2024_data, esg_2025, on = [\"Year\", \"Symbol\", \"Name\", \"Sector\", \"Industry\", \"Country\", \"Market_Cap\", \"IPO_Year\", \"Total_ESG\", \"Environmental\", \"Social\", \"Governance\", \"Controversy\"], how = \"outer\")\n\n\nall_esg\n\n\n  \n    \n\n\n\n\n\n\nYear\nSymbol\nName\nSector\nIndustry\nCountry\nMarket_Cap\nIPO_Year\nTotal_ESG\nEnvironmental\nSocial\nGovernance\nControversy\n\n\n\n\n0\n2024\nA\nAgilent Technologies Inc. Common Stock\nIndustrials\nBiotechnology: Laboratory Analytical Instruments\nUnited States\n4.036543e+10\n1999.0\n13.6\n1.1\n6.4\n6.1\n2.0\n\n\n1\n2024\nAA\nAlcoa Corporation Common Stock\nIndustrials\nAluminum\nUnited States\n6.622136e+09\n2016.0\n24.0\n13.8\n5.9\n4.3\n3.0\n\n\n2\n2024\nAAL\nAmerican Airlines Group Inc. Common Stock\nConsumer Discretionary\nAir Freight/Delivery Services\nUnited States\n9.088025e+09\nNaN\n26.4\n9.9\n11.6\n4.8\n2.0\n\n\n3\n2024\nAAP\nAdvance Auto Parts Inc.\nConsumer Discretionary\nAuto & Home Supply Stores\nUnited States\n4.474665e+09\nNaN\n11.5\n0.1\n8.3\n3.1\n2.0\n\n\n4\n2024\nAAPL\nApple Inc. Common Stock\nTechnology\nComputer Manufacturing\nUnited States\n2.614310e+12\n1980.0\n17.2\n0.5\n7.4\n9.4\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1245\n2025\nXYL\nXylem Inc. Common Stock New\nIndustrials\nFluid Controls\nUnited States\n2.965650e+10\n2011.0\n18.1\n4.3\n8.7\n5.2\n1.0\n\n\n1246\n2025\nYUM\nYum! Brands Inc.\nConsumer Discretionary\nRestaurants\nUnited States\n4.400042e+10\nNaN\n20.1\n4.5\n11.4\n4.1\n2.0\n\n\n1247\n2025\nZ\nZillow Group Inc. Class C Capital Stock\nConsumer Discretionary\nBusiness Services\nUnited States\n1.706396e+10\nNaN\n22.2\n1.2\n11.5\n9.5\n2.0\n\n\n1248\n2025\nZBH\nZimmer Biomet Holdings Inc. Common Stock\nHealth Care\nIndustrial Specialties\nUnited States\n2.232493e+10\nNaN\n26.0\n3.6\n14.5\n7.9\n2.0\n\n\n1249\n2025\nZTS\nZoetis Inc. Class A Common Stock\nHealth Care\nBiotechnology: Pharmaceutical Preparations\nUnited States\n7.389462e+10\n2013.0\n18.8\n3.2\n6.8\n8.7\n2.0\n\n\n\n\n1250 rows × 13 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nall_esg.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1250 entries, 0 to 1249\nData columns (total 13 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   Year           1250 non-null   int64  \n 1   Symbol         1250 non-null   object \n 2   Name           1250 non-null   object \n 3   Sector         1250 non-null   object \n 4   Industry       1250 non-null   object \n 5   Country        1246 non-null   object \n 6   Market_Cap     1250 non-null   float64\n 7   IPO_Year       402 non-null    float64\n 8   Total_ESG      1250 non-null   float64\n 9   Environmental  1204 non-null   float64\n 10  Social         1204 non-null   float64\n 11  Governance     1204 non-null   float64\n 12  Controversy    1146 non-null   float64\ndtypes: float64(7), int64(1), object(5)\nmemory usage: 127.1+ KB\n\n\n\nsectors = all_esg.groupby('Sector')[\"Total_ESG\"].mean()\n\n\nsectors_df = pd.DataFrame(sectors)\nsectors_df.sort_values(\"Total_ESG\", ascending = False)\n\n\n  \n    \n\n\n\n\n\n\nTotal_ESG\n\n\nSector\n\n\n\n\n\nEnergy\n32.788000\n\n\nUtilities\n26.547619\n\n\nConsumer Staples\n26.359091\n\n\nIndustrials\n23.678947\n\n\nHealth Care\n22.815789\n\n\nFinance\n21.754737\n\n\nBasic Materials\n21.750000\n\n\nTelecommunications\n20.406250\n\n\nConsumer Discretionary\n19.588158\n\n\nTechnology\n18.129577\n\n\nReal Estate\n13.880952\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\nenergy = all_esg['Sector'] == \"Energy\"\nenergy = all_esg[energy]\nindustry_esg = energy.groupby(\"Industry\")[\"Total_ESG\"].mean()\nindustry_esg\n\n\n\n\n\n\n\n\nTotal_ESG\n\n\nIndustry\n\n\n\n\n\nIntegrated oil Companies\n34.788889\n\n\nNatural Gas Distribution\n21.100000\n\n\nOil & Gas Production\n33.815385\n\n\nOilfield Services/Equipment\n22.950000\n\n\n\n\ndtype: float64\n\n\n\nindustry_market_cap = energy.groupby(\"Industry\")[\"Market_Cap\"].mean()\nindustry_market_cap\n\n\n\n\n\n\n\n\nMarket_Cap\n\n\nIndustry\n\n\n\n\n\nIntegrated oil Companies\n1.372203e+11\n\n\nNatural Gas Distribution\n8.637729e+10\n\n\nOil & Gas Production\n2.829162e+10\n\n\nOilfield Services/Equipment\n4.644217e+10\n\n\n\n\ndtype: float64\n\n\n\nControv_env = all_esg.groupby(\"Controversy\")[\"Environmental\"].mean()\nControv_env\n\n\n\n\n\n\n\n\nEnvironmental\n\n\nControversy\n\n\n\n\n\n0.0\n5.560000\n\n\n1.0\n5.136076\n\n\n2.0\n5.857762\n\n\n3.0\n6.397030\n\n\n4.0\n6.778571\n\n\n5.0\n9.600000\n\n\n\n\ndtype: float64"
  },
  {
    "objectID": "posts/project/Sustainability_in_Industries_Project.html#exploratory-analysis-data-visualization",
    "href": "posts/project/Sustainability_in_Industries_Project.html#exploratory-analysis-data-visualization",
    "title": "Sustainability in Industries Project",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\nWhat sectors have the highest ESG scores and why might that be? How does that change across years?\n\nsns.boxplot(data = all_esg,\n            y = 'Sector',\n            x = 'Total_ESG',\n            hue = 'Year')\n\n\n\n\n\n\n\n\n\nenergy = all_esg['Sector'] == \"Energy\"\nenergy = all_esg[energy]\n\nWhat energy industries in the Energy Sector have the worst ESG scores?\n\nsns.boxplot(data = energy,\n            y = 'Industry',\n            x = 'Total_ESG',\n            hue = 'Year')\n\n\n\n\n\n\n\n\nWhat are the market capitalizations of energy industries?\n\nsns.boxplot(data = energy,\n            y = 'Industry',\n            x = 'Market_Cap',\n            hue = 'Year')\n\n\n\n\n\n\n\n\nWhat is the relationship between ESG scores and market growth?\n\nsns.lineplot(data = all_esg,\n            x = 'Total_ESG',\n            y = 'Market_Cap')\n\n\n\n\n\n\n\n\nIs there a clear relationship between environmental scores and controversy scores?\n\nsns.boxplot(data = all_esg,\n            x = 'Controversy',\n            y = 'Environmental')"
  },
  {
    "objectID": "posts/project/Sustainability_in_Industries_Project.html#references",
    "href": "posts/project/Sustainability_in_Industries_Project.html#references",
    "title": "Sustainability in Industries Project",
    "section": "# References",
    "text": "# References\nhttps://online.hbs.edu/blog/post/business-sustainability-strategies\nMalene Comeau collaborated on sections data collection, project statement, some descriptive statistics, and some exploratory analysis.\nCopilot was used to attempt to clean the stock data."
  },
  {
    "objectID": "posts/project/danl_210_stang_sophia_.html",
    "href": "posts/project/danl_210_stang_sophia_.html",
    "title": "Sustainability in Industries Project",
    "section": "",
    "text": "Sustainability in business is related to both environmental and societal effects of the company. Reinforcing sustainability initiatives is helpful in reducing climate change, income inequality, natural resource depletion, and many more important issues in our current world. In addition to this, sustainability is beneficial to the company itself, causing it to outcompete other less sustainable organizations. The benefits of being a sustainable business include protecting your brand, creating a purpose-driven company, and partaking in the growing sustainability market (Chladek, 2019).\n##Statement of the Problem: Clearly articulate the specific problem or issue the project will address.\nThis project aims to determine which sectors and industries are most harmful to the environment and determine the connection between environmental safety and market growth. The project also will test whether environmental safety is related to the public controversy level of the industry.\n\n\n\nSet Up: Import packages and data\n\nimport pandas as pd\nurl_2024 = \"https://bcdanl.github.io/data/esg_proj_2024_data.csv\"\nesg_proj_2024_data = pd.read_csv(url_2024)\nurl_2025 = \"https://bcdanl.github.io/data/esg_proj_2025.csv\"\nesg_proj_2025 = pd.read_csv(url_2025)\nesg_2025_dropd = esg_proj_2025.drop_duplicates(subset = [\"Name\"])\nesg_2024_2025 = pd.merge(esg_2025_dropd, esg_proj_2024_data,on = 'Name', how = 'inner')\nurl = \"https://bcdanl.github.io/data/stock_history_2023.csv\"\nstock_history_2023 = pd.read_csv(url)\nesg_2025 = pd.read_csv(\"danl_210_stang_sophia_ESG.csv\")\nstock = pd.read_csv('danl_210_stang_sophia_stock.csv')\n\n\nstock = stock.drop(columns = \"Unnamed: 0\")\n\n\nstock\n\n\n  \n    \n\n\n\n\n\n\nInfo\nDate\nOpen\nHigh\nLow\nClose\nAdj_close\nSymbol\n\n\n\n\n0\nMar 31, 2025 116.36 117.73 113.76 116.98 116.7...\nMar 31, 2025\n116.36\n117.73\n113.76\n116.98\n116.73\nA\n\n\n1\nMar 31, 2025 29.74 30.63 28.80 30.50 30.50 4,9...\nMar 31, 2025\n29.74\n30.63\n28.80\n30.50\n30.50\nAA\n\n\n2\nMar 31, 2025 10.41 10.68 10.06 10.55 10.55 66,...\nMar 31, 2025\n10.41\n10.68\n10.06\n10.55\n10.55\nAAL\n\n\n3\nMar 31, 2025 38.36 39.65 38.25 39.21 38.91 2,3...\nMar 31, 2025\n38.36\n39.65\n38.25\n39.21\n38.91\nAAP\n\n\n4\nMar 31, 2025 217.01 225.62 216.23 222.13 222.1...\nMar 31, 2025\n217.01\n225.62\n216.23\n222.13\n222.13\nAAPL\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n620\nMar 31, 2025 118.64 120.11 116.52 119.46 119.4...\nMar 31, 2025\n118.64\n120.11\n116.52\n119.46\n119.46\nXYL\n\n\n621\nMar 31, 2025 154.18 158.14 153.61 157.36 157.3...\nMar 31, 2025\n154.18\n158.14\n153.61\n157.36\n157.36\nYUM\n\n\n622\nMar 31, 2025 67.54 68.90 66.13 68.56 68.56 2,3...\nMar 31, 2025\n67.54\n68.90\n66.13\n68.56\n68.56\nZ\n\n\n623\nMar 31, 2025 111.37 113.64 111.37 113.18 113.1...\nMar 31, 2025\n111.37\n113.64\n111.37\n113.18\n113.18\nZBH\n\n\n624\nMar 31, 2025 163.12 164.90 161.58 164.65 164.1...\nMar 31, 2025\n163.12\n164.90\n161.58\n164.65\n164.10\nZTS\n\n\n\n\n625 rows × 8 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nesg_2025 = esg_2025.drop(columns = [\"Unnamed: 0\"])\n\n\nesg_2025\n\n\n  \n    \n\n\n\n\n\n\nYear\nSymbol\nName\nSector\nIndustry\nCountry\nMarket_Cap\nIPO_Year\nTotal_ESG\nEnvironmental\nSocial\nGovernance\nControversy\n\n\n\n\n0\n2025\nA\nAgilent Technologies Inc. Common Stock\nIndustrials\nBiotechnology: Laboratory Analytical Instruments\nUnited States\n3.391867e+10\n1999.0\n13.6\n1.1\n6.4\n6.1\n2.0\n\n\n1\n2025\nAA\nAlcoa Corporation Common Stock\nIndustrials\nAluminum\nUnited States\n8.279121e+09\n2016.0\n24.0\n13.8\n5.9\n4.3\n3.0\n\n\n2\n2025\nAAL\nAmerican Airlines Group Inc. Common Stock\nConsumer Discretionary\nAir Freight/Delivery Services\nUnited States\n7.325392e+09\nNaN\n26.4\n9.9\n11.6\n4.8\n2.0\n\n\n3\n2025\nAAP\nAdvance Auto Parts Inc.\nConsumer Discretionary\nAuto & Home Supply Stores\nUnited States\n2.413841e+09\nNaN\n11.5\n0.1\n8.3\n3.1\n2.0\n\n\n4\n2025\nAAPL\nApple Inc. Common Stock\nTechnology\nComputer Manufacturing\nUnited States\n3.362691e+12\n1980.0\n17.2\n0.5\n7.4\n9.4\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n620\n2025\nXYL\nXylem Inc. Common Stock New\nIndustrials\nFluid Controls\nUnited States\n2.965650e+10\n2011.0\n18.1\n4.3\n8.7\n5.2\n1.0\n\n\n621\n2025\nYUM\nYum! Brands Inc.\nConsumer Discretionary\nRestaurants\nUnited States\n4.400042e+10\nNaN\n20.1\n4.5\n11.4\n4.1\n2.0\n\n\n622\n2025\nZ\nZillow Group Inc. Class C Capital Stock\nConsumer Discretionary\nBusiness Services\nUnited States\n1.706396e+10\nNaN\n22.2\n1.2\n11.5\n9.5\n2.0\n\n\n623\n2025\nZBH\nZimmer Biomet Holdings Inc. Common Stock\nHealth Care\nIndustrial Specialties\nUnited States\n2.232493e+10\nNaN\n26.0\n3.6\n14.5\n7.9\n2.0\n\n\n624\n2025\nZTS\nZoetis Inc. Class A Common Stock\nHealth Care\nBiotechnology: Pharmaceutical Preparations\nUnited States\n7.389462e+10\n2013.0\n18.8\n3.2\n6.8\n8.7\n2.0\n\n\n\n\n625 rows × 13 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\nMerge All ESG Data\n\nall_esg = pd.merge(esg_proj_2024_data, esg_2025, on = [\"Year\", \"Symbol\", \"Name\", \"Sector\", \"Industry\", \"Country\", \"Market_Cap\", \"IPO_Year\", \"Total_ESG\", \"Environmental\", \"Social\", \"Governance\", \"Controversy\"], how = \"outer\")\n\n\nall_esg\n\n\n  \n    \n\n\n\n\n\n\nYear\nSymbol\nName\nSector\nIndustry\nCountry\nMarket_Cap\nIPO_Year\nTotal_ESG\nEnvironmental\nSocial\nGovernance\nControversy\n\n\n\n\n0\n2024\nA\nAgilent Technologies Inc. Common Stock\nIndustrials\nBiotechnology: Laboratory Analytical Instruments\nUnited States\n4.036543e+10\n1999.0\n13.6\n1.1\n6.4\n6.1\n2.0\n\n\n1\n2024\nAA\nAlcoa Corporation Common Stock\nIndustrials\nAluminum\nUnited States\n6.622136e+09\n2016.0\n24.0\n13.8\n5.9\n4.3\n3.0\n\n\n2\n2024\nAAL\nAmerican Airlines Group Inc. Common Stock\nConsumer Discretionary\nAir Freight/Delivery Services\nUnited States\n9.088025e+09\nNaN\n26.4\n9.9\n11.6\n4.8\n2.0\n\n\n3\n2024\nAAP\nAdvance Auto Parts Inc.\nConsumer Discretionary\nAuto & Home Supply Stores\nUnited States\n4.474665e+09\nNaN\n11.5\n0.1\n8.3\n3.1\n2.0\n\n\n4\n2024\nAAPL\nApple Inc. Common Stock\nTechnology\nComputer Manufacturing\nUnited States\n2.614310e+12\n1980.0\n17.2\n0.5\n7.4\n9.4\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1245\n2025\nXYL\nXylem Inc. Common Stock New\nIndustrials\nFluid Controls\nUnited States\n2.965650e+10\n2011.0\n18.1\n4.3\n8.7\n5.2\n1.0\n\n\n1246\n2025\nYUM\nYum! Brands Inc.\nConsumer Discretionary\nRestaurants\nUnited States\n4.400042e+10\nNaN\n20.1\n4.5\n11.4\n4.1\n2.0\n\n\n1247\n2025\nZ\nZillow Group Inc. Class C Capital Stock\nConsumer Discretionary\nBusiness Services\nUnited States\n1.706396e+10\nNaN\n22.2\n1.2\n11.5\n9.5\n2.0\n\n\n1248\n2025\nZBH\nZimmer Biomet Holdings Inc. Common Stock\nHealth Care\nIndustrial Specialties\nUnited States\n2.232493e+10\nNaN\n26.0\n3.6\n14.5\n7.9\n2.0\n\n\n1249\n2025\nZTS\nZoetis Inc. Class A Common Stock\nHealth Care\nBiotechnology: Pharmaceutical Preparations\nUnited States\n7.389462e+10\n2013.0\n18.8\n3.2\n6.8\n8.7\n2.0\n\n\n\n\n1250 rows × 13 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nall_esg.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1250 entries, 0 to 1249\nData columns (total 13 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   Year           1250 non-null   int64  \n 1   Symbol         1250 non-null   object \n 2   Name           1250 non-null   object \n 3   Sector         1250 non-null   object \n 4   Industry       1250 non-null   object \n 5   Country        1246 non-null   object \n 6   Market_Cap     1250 non-null   float64\n 7   IPO_Year       402 non-null    float64\n 8   Total_ESG      1250 non-null   float64\n 9   Environmental  1204 non-null   float64\n 10  Social         1204 non-null   float64\n 11  Governance     1204 non-null   float64\n 12  Controversy    1146 non-null   float64\ndtypes: float64(7), int64(1), object(5)\nmemory usage: 127.1+ KB\n\n\n\nsectors = all_esg.groupby('Sector')[\"Total_ESG\"].mean()\n\n\nsectors_df = pd.DataFrame(sectors)\nsectors_df.sort_values(\"Total_ESG\", ascending = False)\n\n\n  \n    \n\n\n\n\n\n\nTotal_ESG\n\n\nSector\n\n\n\n\n\nEnergy\n32.788000\n\n\nUtilities\n26.547619\n\n\nConsumer Staples\n26.359091\n\n\nIndustrials\n23.678947\n\n\nHealth Care\n22.815789\n\n\nFinance\n21.754737\n\n\nBasic Materials\n21.750000\n\n\nTelecommunications\n20.406250\n\n\nConsumer Discretionary\n19.588158\n\n\nTechnology\n18.129577\n\n\nReal Estate\n13.880952\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\nenergy = all_esg['Sector'] == \"Energy\"\nenergy = all_esg[energy]\nindustry_esg = energy.groupby(\"Industry\")[\"Total_ESG\"].mean()\nindustry_esg\n\n\n\n\n\n\n\n\nTotal_ESG\n\n\nIndustry\n\n\n\n\n\nIntegrated oil Companies\n34.788889\n\n\nNatural Gas Distribution\n21.100000\n\n\nOil & Gas Production\n33.815385\n\n\nOilfield Services/Equipment\n22.950000\n\n\n\n\ndtype: float64\n\n\n\nindustry_market_cap = energy.groupby(\"Industry\")[\"Market_Cap\"].mean()\nindustry_market_cap\n\n\n\n\n\n\n\n\nMarket_Cap\n\n\nIndustry\n\n\n\n\n\nIntegrated oil Companies\n1.372203e+11\n\n\nNatural Gas Distribution\n8.637729e+10\n\n\nOil & Gas Production\n2.829162e+10\n\n\nOilfield Services/Equipment\n4.644217e+10\n\n\n\n\ndtype: float64\n\n\n\nControv_env = all_esg.groupby(\"Controversy\")[\"Environmental\"].mean()\nControv_env\n\n\n\n\n\n\n\n\nEnvironmental\n\n\nControversy\n\n\n\n\n\n0.0\n5.560000\n\n\n1.0\n5.136076\n\n\n2.0\n5.857762\n\n\n3.0\n6.397030\n\n\n4.0\n6.778571\n\n\n5.0\n9.600000\n\n\n\n\ndtype: float64\n\n\n\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\nWhat sectors have the highest ESG scores and why might that be? How does that change across years?\n\nsns.boxplot(data = all_esg,\n            y = 'Sector',\n            x = 'Total_ESG',\n            hue = 'Year')\n\n\n\n\n\n\n\n\n\nenergy = all_esg['Sector'] == \"Energy\"\nenergy = all_esg[energy]\n\nWhat energy industries in the Energy Sector have the worst ESG scores?\n\nsns.boxplot(data = energy,\n            y = 'Industry',\n            x = 'Total_ESG',\n            hue = 'Year')\n\n\n\n\n\n\n\n\nWhat are the market capitalizations of energy industries?\n\nsns.boxplot(data = energy,\n            y = 'Industry',\n            x = 'Market_Cap',\n            hue = 'Year')\n\n\n\n\n\n\n\n\nWhat is the relationship between ESG scores and market growth?\n\nsns.lineplot(data = all_esg,\n            x = 'Total_ESG',\n            y = 'Market_Cap')\n\n\n\n\n\n\n\n\nIs there a clear relationship between environmental scores and controversy scores?\n\nsns.boxplot(data = all_esg,\n            x = 'Controversy',\n            y = 'Environmental')"
  },
  {
    "objectID": "posts/project/danl_210_stang_sophia_.html#background-provide-context-for-the-research-questions-explaining-why-they-are-significant-relevant-or-interesting.",
    "href": "posts/project/danl_210_stang_sophia_.html#background-provide-context-for-the-research-questions-explaining-why-they-are-significant-relevant-or-interesting.",
    "title": "Sustainability in Industries Project",
    "section": "",
    "text": "Sustainability in business is related to both environmental and societal effects of the company. Reinforcing sustainability initiatives is helpful in reducing climate change, income inequality, natural resource depletion, and many more important issues in our current world. In addition to this, sustainability is beneficial to the company itself, causing it to outcompete other less sustainable organizations. The benefits of being a sustainable business include protecting your brand, creating a purpose-driven company, and partaking in the growing sustainability market (Chladek, 2019).\n##Statement of the Problem: Clearly articulate the specific problem or issue the project will address.\nThis project aims to determine which sectors and industries are most harmful to the environment and determine the connection between environmental safety and market growth. The project also will test whether environmental safety is related to the public controversy level of the industry."
  },
  {
    "objectID": "posts/project/danl_210_stang_sophia_.html#descriptive-statistics",
    "href": "posts/project/danl_210_stang_sophia_.html#descriptive-statistics",
    "title": "Sustainability in Industries Project",
    "section": "",
    "text": "Set Up: Import packages and data\n\nimport pandas as pd\nurl_2024 = \"https://bcdanl.github.io/data/esg_proj_2024_data.csv\"\nesg_proj_2024_data = pd.read_csv(url_2024)\nurl_2025 = \"https://bcdanl.github.io/data/esg_proj_2025.csv\"\nesg_proj_2025 = pd.read_csv(url_2025)\nesg_2025_dropd = esg_proj_2025.drop_duplicates(subset = [\"Name\"])\nesg_2024_2025 = pd.merge(esg_2025_dropd, esg_proj_2024_data,on = 'Name', how = 'inner')\nurl = \"https://bcdanl.github.io/data/stock_history_2023.csv\"\nstock_history_2023 = pd.read_csv(url)\nesg_2025 = pd.read_csv(\"danl_210_stang_sophia_ESG.csv\")\nstock = pd.read_csv('danl_210_stang_sophia_stock.csv')\n\n\nstock = stock.drop(columns = \"Unnamed: 0\")\n\n\nstock\n\n\n  \n    \n\n\n\n\n\n\nInfo\nDate\nOpen\nHigh\nLow\nClose\nAdj_close\nSymbol\n\n\n\n\n0\nMar 31, 2025 116.36 117.73 113.76 116.98 116.7...\nMar 31, 2025\n116.36\n117.73\n113.76\n116.98\n116.73\nA\n\n\n1\nMar 31, 2025 29.74 30.63 28.80 30.50 30.50 4,9...\nMar 31, 2025\n29.74\n30.63\n28.80\n30.50\n30.50\nAA\n\n\n2\nMar 31, 2025 10.41 10.68 10.06 10.55 10.55 66,...\nMar 31, 2025\n10.41\n10.68\n10.06\n10.55\n10.55\nAAL\n\n\n3\nMar 31, 2025 38.36 39.65 38.25 39.21 38.91 2,3...\nMar 31, 2025\n38.36\n39.65\n38.25\n39.21\n38.91\nAAP\n\n\n4\nMar 31, 2025 217.01 225.62 216.23 222.13 222.1...\nMar 31, 2025\n217.01\n225.62\n216.23\n222.13\n222.13\nAAPL\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n620\nMar 31, 2025 118.64 120.11 116.52 119.46 119.4...\nMar 31, 2025\n118.64\n120.11\n116.52\n119.46\n119.46\nXYL\n\n\n621\nMar 31, 2025 154.18 158.14 153.61 157.36 157.3...\nMar 31, 2025\n154.18\n158.14\n153.61\n157.36\n157.36\nYUM\n\n\n622\nMar 31, 2025 67.54 68.90 66.13 68.56 68.56 2,3...\nMar 31, 2025\n67.54\n68.90\n66.13\n68.56\n68.56\nZ\n\n\n623\nMar 31, 2025 111.37 113.64 111.37 113.18 113.1...\nMar 31, 2025\n111.37\n113.64\n111.37\n113.18\n113.18\nZBH\n\n\n624\nMar 31, 2025 163.12 164.90 161.58 164.65 164.1...\nMar 31, 2025\n163.12\n164.90\n161.58\n164.65\n164.10\nZTS\n\n\n\n\n625 rows × 8 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nesg_2025 = esg_2025.drop(columns = [\"Unnamed: 0\"])\n\n\nesg_2025\n\n\n  \n    \n\n\n\n\n\n\nYear\nSymbol\nName\nSector\nIndustry\nCountry\nMarket_Cap\nIPO_Year\nTotal_ESG\nEnvironmental\nSocial\nGovernance\nControversy\n\n\n\n\n0\n2025\nA\nAgilent Technologies Inc. Common Stock\nIndustrials\nBiotechnology: Laboratory Analytical Instruments\nUnited States\n3.391867e+10\n1999.0\n13.6\n1.1\n6.4\n6.1\n2.0\n\n\n1\n2025\nAA\nAlcoa Corporation Common Stock\nIndustrials\nAluminum\nUnited States\n8.279121e+09\n2016.0\n24.0\n13.8\n5.9\n4.3\n3.0\n\n\n2\n2025\nAAL\nAmerican Airlines Group Inc. Common Stock\nConsumer Discretionary\nAir Freight/Delivery Services\nUnited States\n7.325392e+09\nNaN\n26.4\n9.9\n11.6\n4.8\n2.0\n\n\n3\n2025\nAAP\nAdvance Auto Parts Inc.\nConsumer Discretionary\nAuto & Home Supply Stores\nUnited States\n2.413841e+09\nNaN\n11.5\n0.1\n8.3\n3.1\n2.0\n\n\n4\n2025\nAAPL\nApple Inc. Common Stock\nTechnology\nComputer Manufacturing\nUnited States\n3.362691e+12\n1980.0\n17.2\n0.5\n7.4\n9.4\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n620\n2025\nXYL\nXylem Inc. Common Stock New\nIndustrials\nFluid Controls\nUnited States\n2.965650e+10\n2011.0\n18.1\n4.3\n8.7\n5.2\n1.0\n\n\n621\n2025\nYUM\nYum! Brands Inc.\nConsumer Discretionary\nRestaurants\nUnited States\n4.400042e+10\nNaN\n20.1\n4.5\n11.4\n4.1\n2.0\n\n\n622\n2025\nZ\nZillow Group Inc. Class C Capital Stock\nConsumer Discretionary\nBusiness Services\nUnited States\n1.706396e+10\nNaN\n22.2\n1.2\n11.5\n9.5\n2.0\n\n\n623\n2025\nZBH\nZimmer Biomet Holdings Inc. Common Stock\nHealth Care\nIndustrial Specialties\nUnited States\n2.232493e+10\nNaN\n26.0\n3.6\n14.5\n7.9\n2.0\n\n\n624\n2025\nZTS\nZoetis Inc. Class A Common Stock\nHealth Care\nBiotechnology: Pharmaceutical Preparations\nUnited States\n7.389462e+10\n2013.0\n18.8\n3.2\n6.8\n8.7\n2.0\n\n\n\n\n625 rows × 13 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\nMerge All ESG Data\n\nall_esg = pd.merge(esg_proj_2024_data, esg_2025, on = [\"Year\", \"Symbol\", \"Name\", \"Sector\", \"Industry\", \"Country\", \"Market_Cap\", \"IPO_Year\", \"Total_ESG\", \"Environmental\", \"Social\", \"Governance\", \"Controversy\"], how = \"outer\")\n\n\nall_esg\n\n\n  \n    \n\n\n\n\n\n\nYear\nSymbol\nName\nSector\nIndustry\nCountry\nMarket_Cap\nIPO_Year\nTotal_ESG\nEnvironmental\nSocial\nGovernance\nControversy\n\n\n\n\n0\n2024\nA\nAgilent Technologies Inc. Common Stock\nIndustrials\nBiotechnology: Laboratory Analytical Instruments\nUnited States\n4.036543e+10\n1999.0\n13.6\n1.1\n6.4\n6.1\n2.0\n\n\n1\n2024\nAA\nAlcoa Corporation Common Stock\nIndustrials\nAluminum\nUnited States\n6.622136e+09\n2016.0\n24.0\n13.8\n5.9\n4.3\n3.0\n\n\n2\n2024\nAAL\nAmerican Airlines Group Inc. Common Stock\nConsumer Discretionary\nAir Freight/Delivery Services\nUnited States\n9.088025e+09\nNaN\n26.4\n9.9\n11.6\n4.8\n2.0\n\n\n3\n2024\nAAP\nAdvance Auto Parts Inc.\nConsumer Discretionary\nAuto & Home Supply Stores\nUnited States\n4.474665e+09\nNaN\n11.5\n0.1\n8.3\n3.1\n2.0\n\n\n4\n2024\nAAPL\nApple Inc. Common Stock\nTechnology\nComputer Manufacturing\nUnited States\n2.614310e+12\n1980.0\n17.2\n0.5\n7.4\n9.4\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1245\n2025\nXYL\nXylem Inc. Common Stock New\nIndustrials\nFluid Controls\nUnited States\n2.965650e+10\n2011.0\n18.1\n4.3\n8.7\n5.2\n1.0\n\n\n1246\n2025\nYUM\nYum! Brands Inc.\nConsumer Discretionary\nRestaurants\nUnited States\n4.400042e+10\nNaN\n20.1\n4.5\n11.4\n4.1\n2.0\n\n\n1247\n2025\nZ\nZillow Group Inc. Class C Capital Stock\nConsumer Discretionary\nBusiness Services\nUnited States\n1.706396e+10\nNaN\n22.2\n1.2\n11.5\n9.5\n2.0\n\n\n1248\n2025\nZBH\nZimmer Biomet Holdings Inc. Common Stock\nHealth Care\nIndustrial Specialties\nUnited States\n2.232493e+10\nNaN\n26.0\n3.6\n14.5\n7.9\n2.0\n\n\n1249\n2025\nZTS\nZoetis Inc. Class A Common Stock\nHealth Care\nBiotechnology: Pharmaceutical Preparations\nUnited States\n7.389462e+10\n2013.0\n18.8\n3.2\n6.8\n8.7\n2.0\n\n\n\n\n1250 rows × 13 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nall_esg.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1250 entries, 0 to 1249\nData columns (total 13 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   Year           1250 non-null   int64  \n 1   Symbol         1250 non-null   object \n 2   Name           1250 non-null   object \n 3   Sector         1250 non-null   object \n 4   Industry       1250 non-null   object \n 5   Country        1246 non-null   object \n 6   Market_Cap     1250 non-null   float64\n 7   IPO_Year       402 non-null    float64\n 8   Total_ESG      1250 non-null   float64\n 9   Environmental  1204 non-null   float64\n 10  Social         1204 non-null   float64\n 11  Governance     1204 non-null   float64\n 12  Controversy    1146 non-null   float64\ndtypes: float64(7), int64(1), object(5)\nmemory usage: 127.1+ KB\n\n\n\nsectors = all_esg.groupby('Sector')[\"Total_ESG\"].mean()\n\n\nsectors_df = pd.DataFrame(sectors)\nsectors_df.sort_values(\"Total_ESG\", ascending = False)\n\n\n  \n    \n\n\n\n\n\n\nTotal_ESG\n\n\nSector\n\n\n\n\n\nEnergy\n32.788000\n\n\nUtilities\n26.547619\n\n\nConsumer Staples\n26.359091\n\n\nIndustrials\n23.678947\n\n\nHealth Care\n22.815789\n\n\nFinance\n21.754737\n\n\nBasic Materials\n21.750000\n\n\nTelecommunications\n20.406250\n\n\nConsumer Discretionary\n19.588158\n\n\nTechnology\n18.129577\n\n\nReal Estate\n13.880952\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\nenergy = all_esg['Sector'] == \"Energy\"\nenergy = all_esg[energy]\nindustry_esg = energy.groupby(\"Industry\")[\"Total_ESG\"].mean()\nindustry_esg\n\n\n\n\n\n\n\n\nTotal_ESG\n\n\nIndustry\n\n\n\n\n\nIntegrated oil Companies\n34.788889\n\n\nNatural Gas Distribution\n21.100000\n\n\nOil & Gas Production\n33.815385\n\n\nOilfield Services/Equipment\n22.950000\n\n\n\n\ndtype: float64\n\n\n\nindustry_market_cap = energy.groupby(\"Industry\")[\"Market_Cap\"].mean()\nindustry_market_cap\n\n\n\n\n\n\n\n\nMarket_Cap\n\n\nIndustry\n\n\n\n\n\nIntegrated oil Companies\n1.372203e+11\n\n\nNatural Gas Distribution\n8.637729e+10\n\n\nOil & Gas Production\n2.829162e+10\n\n\nOilfield Services/Equipment\n4.644217e+10\n\n\n\n\ndtype: float64\n\n\n\nControv_env = all_esg.groupby(\"Controversy\")[\"Environmental\"].mean()\nControv_env\n\n\n\n\n\n\n\n\nEnvironmental\n\n\nControversy\n\n\n\n\n\n0.0\n5.560000\n\n\n1.0\n5.136076\n\n\n2.0\n5.857762\n\n\n3.0\n6.397030\n\n\n4.0\n6.778571\n\n\n5.0\n9.600000\n\n\n\n\ndtype: float64"
  },
  {
    "objectID": "posts/project/danl_210_stang_sophia_.html#exploratory-analysis-data-visualization",
    "href": "posts/project/danl_210_stang_sophia_.html#exploratory-analysis-data-visualization",
    "title": "Sustainability in Industries Project",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\nWhat sectors have the highest ESG scores and why might that be? How does that change across years?\n\nsns.boxplot(data = all_esg,\n            y = 'Sector',\n            x = 'Total_ESG',\n            hue = 'Year')\n\n\n\n\n\n\n\n\n\nenergy = all_esg['Sector'] == \"Energy\"\nenergy = all_esg[energy]\n\nWhat energy industries in the Energy Sector have the worst ESG scores?\n\nsns.boxplot(data = energy,\n            y = 'Industry',\n            x = 'Total_ESG',\n            hue = 'Year')\n\n\n\n\n\n\n\n\nWhat are the market capitalizations of energy industries?\n\nsns.boxplot(data = energy,\n            y = 'Industry',\n            x = 'Market_Cap',\n            hue = 'Year')\n\n\n\n\n\n\n\n\nWhat is the relationship between ESG scores and market growth?\n\nsns.lineplot(data = all_esg,\n            x = 'Total_ESG',\n            y = 'Market_Cap')\n\n\n\n\n\n\n\n\nIs there a clear relationship between environmental scores and controversy scores?\n\nsns.boxplot(data = all_esg,\n            x = 'Controversy',\n            y = 'Environmental')"
  },
  {
    "objectID": "posts/project/danl_210_stang_sophia_.html#references",
    "href": "posts/project/danl_210_stang_sophia_.html#references",
    "title": "Sustainability in Industries Project",
    "section": "# References",
    "text": "# References\nhttps://online.hbs.edu/blog/post/business-sustainability-strategies\nMalene Comeau collaborated on sections data collection, project statement, some descriptive statistics, and some exploratory analysis.\nCopilot was used to attempt to clean the stock data."
  }
]